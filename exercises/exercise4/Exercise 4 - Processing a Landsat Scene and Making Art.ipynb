{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Processing a Landsat Scene into Art\n",
    "\n",
    "In this exercise, we will process a landsat scene directly from the raw GeoTiff, hosted on AWS. This is different then the Landsat Scene data we've been interacting with in the earlier exercises, which had been pre-processed by GeoTrellis into a GeoTrellis Layer.\n",
    "\n",
    "After we grab process the landsat scene, we'll combine it with [NED](https://lta.cr.usgs.gov/NED) and [NLCD](https://catalog.data.gov/dataset/national-land-cover-database-nlcd-land-cover-collection) data and adjust coloring via [rio_color](https://github.com/mapbox/rio-color/tree/master/rio_color) to make a cool looking map layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import osr\n",
    "import rasterio.warp\n",
    "import geopyspark as gps\n",
    "import numpy as np\n",
    "import csv, os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import math\n",
    "from PIL import Image\n",
    "import pyproj\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely.ops import transform\n",
    "from functools import partial\n",
    "import urllib.request, json\n",
    "import dateutil.parser\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark import SparkContext\n",
    "from geonotebook.wrappers import TMSRasterData, GeoJsonData\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "\n",
    "from rasterfoundry.api import API\n",
    "\n",
    "from rio_color.operations import gamma, sigmoidal, saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our spark context\n",
    "conf = gps.geopyspark_conf(appName=\"Exercise 1\") \\\n",
    "          .setMaster(\"local[*]\") \\\n",
    "          .set(key='spark.ui.enabled', value='true') \\\n",
    "          .set(key=\"spark.driver.memory\", value=\"8G\") \\\n",
    "          .set(\"spark.hadoop.yarn.timeline-service.enabled\", False)\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the GeoJson for our Area of Interest\n",
    "\n",
    "We can use the annotation tool in GeoNotebook to grab an extent that we are interested in. The location of the tool is in the toolbar, highlighted here:\n",
    "![Annotation tool](files/annotation-tool.png)\n",
    "\n",
    "Draw a small bounding box in an area you'd like to processes a landsat scene for.\n",
    "\n",
    "We can then use GeoNotebook to grab the annotation and get the polygon it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aoi = M.layers.annotation.rectangles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = aoi.centroid\n",
    "M.set_center(p.x, p.y, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Raster Foundry to find Landsast 8 scenes\n",
    "\n",
    "Here we set up a client to read from the [Raster Foundry](https://www.rasterfoundry.com/) API any scenes that match our area of interest over a time in 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = API(refresh_token='47MAq91iWa6xlbqEW5d6uustkslFI75ZaawBdzW2gVoZ0')\n",
    "landsat_8 = client.get_datasources(name='Landsat 8').results[0]\n",
    "\n",
    "min_datetime = datetime(2017, 1, 1).isoformat() + 'Z'\n",
    "max_datetime = datetime(2017, 12, 1).isoformat() + 'Z'\n",
    "bounds = ','.join(map(lambda x: str(x), aoi.bounds))\n",
    "\n",
    "filters = dict(pageSize=250, datasource=[landsat_8.id],\n",
    "                   minAcquisitionDatetime=min_datetime,\n",
    "                   maxAcquisitionDatetime=max_datetime,\n",
    "                   bbox=bounds,\n",
    "                   maxCloudCover=10)\n",
    "\n",
    "# Initial conditions\n",
    "has_next = True\n",
    "page = 0\n",
    "results = []\n",
    "\n",
    "while has_next:\n",
    "    print(\"Processing Page {}\".format(page))\n",
    "    scenes = client.get_scenes(page=page, **filters)\n",
    "    if page == 0:\n",
    "        print('{} scenes total match query'.format(scenes.count))\n",
    "    for scene in scenes.results:\n",
    "        results.append(scene)\n",
    "    page += 1\n",
    "    has_next = scenes.hasNext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking a scene\n",
    "\n",
    "We can use the thumbnail information on the results to browse the scenes and select the one we want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_image(img, name):\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(6, 4)\n",
    "\n",
    "    a = fig.add_subplot(1, 2, 1)\n",
    "    a.set_title(name)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def get_thumbnail(scene, size='SMALL'):\n",
    "    url = list(filter(lambda t: t.thumbnailSize == size, scene.thumbnails))[0].url\n",
    "    file = io.BytesIO(urllib.request.urlopen(url).read())\n",
    "    return Image.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "for i, scene in enumerate(results):\n",
    "    plot_image(get_thumbnail(scene), \"Scene {}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scene = results[5]\n",
    "get_thumbnail(scene, size='LARGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The annotation has done it's job, and we can clear it from the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.layers.annotation.clear_annotations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RDD of Scene information\n",
    "\n",
    "This bit of code grabs the relevant information from the Raster Foundry results for our scene, and parallizes that collection of information into an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convenience tuple to store Scene information for GeoPySpark\n",
    "SceneRow = namedtuple('SceneRow', 'date, scene_id, band, uri')\n",
    "\n",
    "desired_bands = {\n",
    "    # 'coastal aerosol - 1': 0,\n",
    "    'blue - 2': 1,\n",
    "    'green - 3': 2,\n",
    "    'red - 4': 3,\n",
    "    'near infrared - 5': 4,\n",
    "    # 'swir - 6': 5,\n",
    "    # 'swir - 7': 6,\n",
    "    # 'panchromatic - 8': 7,\n",
    "    # 'cirrus - 9': 8,\n",
    "    # 'thermal infrared - 10': 9,\n",
    "    # 'thermal infrared - 11': 10,\n",
    "    #'QA': 11\n",
    "}\n",
    "\n",
    "def get_desired_bands(scene):\n",
    "    \"\"\"Convenience function to process desired bands for GeoPySpark\n",
    "\n",
    "    Args:\n",
    "        scene:\n",
    "\n",
    "    Returns:\n",
    "        List[SceneRow]\n",
    "    \"\"\"\n",
    "    acquisition_date = scene.filterFields.acquisitionDate\n",
    "    landsat_8_rows = []\n",
    "    for image in scene.images:\n",
    "        uri = image.sourceUri\n",
    "        band_name = image.bands[0].name\n",
    "        band_num = desired_bands.get(band_name)\n",
    "        if band_num:\n",
    "            row = SceneRow(acquisition_date, scene.name, band_num, uri)\n",
    "            landsat_8_rows.append(row)\n",
    "\n",
    "    return landsat_8_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we parallelize our list of `SceneRow`s so that we can start operating on them in  a distributed RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scene_info = sc.parallelize(get_desired_bands(scene)).repartition(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the metadata of tiled window reads of our rasters\n",
    "\n",
    "This next step gathers the metadata from each of the GeoTiffs on S3, using the feature of GDAL and rasterio that only reads a small range of bytes from the GeoTiff to gather metadata. This sets up the reading of the raster data but does not yet perform it; we will repartition before performing the actual read below in order to more optimally distrbute the data reading tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metadata(row):\n",
    "    with rasterio.open(row.uri) as dataset:\n",
    "        bounds = dataset.bounds\n",
    "        height = dataset.height\n",
    "        width = dataset.width\n",
    "        crs = dataset.get_crs()\n",
    "        srs = osr.SpatialReference()\n",
    "        srs.ImportFromWkt(crs.wkt)\n",
    "        proj4 = srs.ExportToProj4()\n",
    "        tile_cols = math.floor((width - 1) / 512) * 512\n",
    "        tile_rows = math.floor((height - 1) / 512) * 512\n",
    "        ws = [((x, x + 512), (y, y + 512)) for x in range(0,tile_cols, 512) \\\n",
    "                                          for y in range(0, tile_rows, 512)]\n",
    "\n",
    "    def windows(row, ws):\n",
    "        for w in ws:\n",
    "            ((row_start, row_stop), (col_start, col_stop)) = w\n",
    "\n",
    "            left  = bounds.left + (bounds.right - bounds.left)*(float(col_start)/width)\n",
    "            right = bounds.left + (bounds.right - bounds.left)*(float(col_stop)/ width)\n",
    "            bottom = bounds.top + (bounds.bottom - bounds.top)*(float(row_stop)/height)\n",
    "            top = bounds.top + (bounds.bottom - bounds.top)*(float(row_start)/height)\n",
    "            extent = gps.Extent(left,bottom,right,top)\n",
    "            instant = datetime.strptime(row.date, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "            projected_extent = gps.TemporalProjectedExtent(extent=extent, \n",
    "                                                            instant=instant, \n",
    "                                                            proj4=proj4)\n",
    "            window_info = { 'scene_id': row.scene_id, \n",
    "                            'band': row.band, \n",
    "                            'uri': row.uri,\n",
    "                            'window': w,\n",
    "                            'projected_extent': projected_extent,\n",
    "                            'tile_key': (row_start, col_start) }\n",
    "\n",
    "            yield window_info\n",
    "    \n",
    "    return [i for i in windows(row, ws)]\n",
    "\n",
    "scene_window_metadata = scene_info.flatMap(get_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the raster data from each GeoTiff\n",
    "\n",
    "Here we repartition the data and map our values to actual raster data read from rasterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(line):\n",
    "    \n",
    "    new_line = line.copy()\n",
    "\n",
    "    with rasterio.open(line['uri']) as dataset:\n",
    "        new_line['data'] = dataset.read(1, window=line['window'])\n",
    "        new_line.pop('window')\n",
    "        new_line.pop('uri')\n",
    "    \n",
    "    return new_line\n",
    "\n",
    "scene_band_tiles = scene_window_metadata.repartition(500).map(get_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gather bands of the same scene\n",
    "\n",
    "Landsat stores each of it's bands individually in seperate, single band GeoTiff files. We can use the `scene_id` to group the RDD by key, and merge the bands to create a single multiband tile per scene per tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_band_tiles = \\\n",
    "  scene_band_tiles.groupBy(lambda line: (line['scene_id'], line['tile_key']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the bands are grouped, use the `make_tilee` method to generate the multiband tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_tile(grouped):\n",
    "    lines = list(grouped[1])\n",
    "    projected_extent = lines[0]['projected_extent']\n",
    "    try:\n",
    "        array = np.array([l['data'] for l in sorted(lines, key=lambda l: int(l['band']))])\n",
    "        if array.dtype == 'object':\n",
    "            bandshapes = [str(l['data'].shape) for l in sorted(lines, key=lambda l: l['band'])]\n",
    "            raise Exception(\"{}\".format('\\n'.join(bandshapes)))\n",
    "    except:\n",
    "        bandshapes = [\"{} - {}\".format(l['band'], l['data'].shape) for l in sorted(lines, key=lambda l: l['band'])]\n",
    "        raise Exception(\"ER {}\".format('\\n'.join(bandshapes)))\n",
    "    tile = gps.Tile.from_numpy_array(array, no_data_value=0.0)\n",
    "    return (projected_extent, tile)\n",
    "\n",
    "combined_tiles = grouped_band_tiles.map(make_tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reproject and ReTile into a GeoTrellis layer\n",
    "\n",
    "Now that we've transformed our data into an RDD containing tuples of `ProjectedExtent` and `Tile`, we can transfer the values over to GeoTrellis types\n",
    "on the JVM and use GeoPySpark to create a pyramided layer in EPSG:3857 from our scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raster_layer = gps.RasterLayer.from_numpy_rdd(gps.LayerType.SPACETIME, combined_tiles)\n",
    "tiled_raster_layer = raster_layer.tile_to_layout(layout = gps.GlobalLayout(), target_crs=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "landsat_layer = tiled_raster_layer.to_spatial_layer()\n",
    "landsat_pyramid = landsat_layer \\\n",
    "                    .repartition(100) \\\n",
    "                    .pyramid(resample_method=gps.ResampleMethod.BILINEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Note: This is where we would write our layer\n",
    "\n",
    "At this point, we are could be at the end of an ingest script. We would write our layer out to a supported GeoTrellis backend with code like: \n",
    "```python\n",
    "for layer in sorted(pyramid.levels.values(), key=lambda l: -l.zoom_level):\n",
    "    gps.write(\"s3://some/catalog\", \n",
    "              \"my-landsat-image\", \n",
    "              layer)\n",
    "```\n",
    "\n",
    "However, we're going to keep going with the pyramided RDD and rely on Spark to keep it stored in our RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering a color corrected version of our scene on the map\n",
    "\n",
    "Similar to the other notebooks, here we use some magic numbers to generate a\n",
    "simply color corrected version of our scene on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def landsat_rgba(tile):\n",
    "    cells = tile.cells\n",
    "    # Color correct - use magic numbers\n",
    "    magic_min, magic_max = 4000, 15176\n",
    "    norm_range = magic_max - magic_min\n",
    "    cells = cells.astype('int32')\n",
    "    # Clamp cells\n",
    "    cells[(cells != 0) & (cells < magic_min)] = magic_min\n",
    "    cells[(cells != 0) & (cells > magic_max)] = magic_max\n",
    "    colored = ((cells - magic_min) * 255) / norm_range\n",
    "    r, g, b = (colored[2], colored[1], colored[0])\n",
    "    alpha = np.full(r.shape, 255)\n",
    "    alpha[(cells[0] == tile.no_data_value) & \\\n",
    "          (cells[1] == tile.no_data_value) & \\\n",
    "          (cells[2] == tile.no_data_value)] = 0\n",
    "    return (r, g, b, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_image(tile):\n",
    "    (r, g, b, alpha) = landsat_rgba(tile)\n",
    "    rgba = np.dstack([r,g,b, alpha]).astype('uint8')\n",
    "    return Image.fromarray(rgba, mode='RGBA')\n",
    "\n",
    "for x in M.layers:\n",
    "    M.remove_layer(x)\n",
    "\n",
    "tms_server = gps.TMS.build(landsat_pyramid, display=render_image)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"landsat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Adding hillshade from the National Elevation Dataset\n",
    "\n",
    "Now this will get a litte more interesting. Let's combine our landsat data with other datasources to modify the images.\n",
    "\n",
    "First, we'll grab elevation data from a layer that was ingested from the [National Elevation Dataset](https://lta.cr.usgs.gov/NED) and compute a [hillshade](https://en.wikipedia.org/wiki/Terrain_cartography#Shaded_relief) over our scene's area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elevation_layer = gps.query(\"s3://azavea-datahub/catalog\", \n",
    "                            \"us-ned-tms-epsg3857\", \n",
    "                            layer_zoom=13,\n",
    "                            query_geom=landsat_layer.layer_metadata.extent.to_polygon,\n",
    "                            num_partitions=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `azimuth`, `altitude` and `z_factor` arguments can be modified to\n",
    "change the look of the map tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hillshade = gps.hillshade(elevation_layer, \n",
    "                          band=0, \n",
    "                          azimuth=99.0, \n",
    "                          altitude=33.0, \n",
    "                          z_factor=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hillshade_pyramid = hillshade.repartition(100).pyramid(resample_method=gps.ResampleMethod.BILINEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the brightness of pixels based on hillshade\n",
    "\n",
    "The following code uses a technique that I first saw [in a blog by\n",
    "Frank Warmerdam](http://fwarmerdam.blogspot.com/2010/01/hsvmergepy.html), who is the creator of GDAL and a FOSS4G legend.\n",
    "\n",
    "We convert RGB values into the HSV color space, modify the brightness (which is the 'value' part of HSV: Hue, Saturation, Value) based on the hillshade value, and then convert back to RGB space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See http://fwarmerdam.blogspot.com/2010/01/hsvmergepy.html\n",
    "# =============================================================================\n",
    "# rgb_to_hsv()\n",
    "#\n",
    "# rgb comes in as [r,g,b] with values in the range [0,255].  The returned\n",
    "# hsv values will be with hue and saturation in the range [0,1] and value\n",
    "# in the range [0,255]\n",
    "#\n",
    "def rgb_to_hsv( r,g,b ):\n",
    "\n",
    "    maxc = np.maximum(r,np.maximum(g,b))\n",
    "    minc = np.minimum(r,np.minimum(g,b))\n",
    "\n",
    "    v = maxc\n",
    "\n",
    "    minc_eq_maxc = np.equal(minc,maxc)\n",
    "\n",
    "    # compute the difference, but reset zeros to ones to avoid divide by zeros later.\n",
    "    ones = np.ones((r.shape[0],r.shape[1]))\n",
    "    maxc_minus_minc = np.choose( minc_eq_maxc, (maxc-minc,ones) )\n",
    "\n",
    "    s = (maxc-minc) / np.maximum(ones,maxc)\n",
    "    rc = (maxc-r) / maxc_minus_minc\n",
    "    gc = (maxc-g) / maxc_minus_minc\n",
    "    bc = (maxc-b) / maxc_minus_minc\n",
    "\n",
    "    maxc_is_r = np.equal(maxc,r)\n",
    "    maxc_is_g = np.equal(maxc,g)\n",
    "    maxc_is_b = np.equal(maxc,b)\n",
    "\n",
    "    h = np.zeros((r.shape[0],r.shape[1]))\n",
    "    h = np.choose( maxc_is_b, (h,4.0+gc-rc) )\n",
    "    h = np.choose( maxc_is_g, (h,2.0+rc-bc) )\n",
    "    h = np.choose( maxc_is_r, (h,bc-gc) )\n",
    "\n",
    "    h = np.mod(h/6.0,1.0)\n",
    "\n",
    "    hsv = np.asarray([h,s,v])\n",
    "\n",
    "    return hsv\n",
    "\n",
    "# =============================================================================\n",
    "# hsv_to_rgb()\n",
    "#\n",
    "# hsv comes in as [h,s,v] with hue and saturation in the range [0,1],\n",
    "# but value in the range [0,255].\n",
    "\n",
    "def hsv_to_rgb( hsv ):\n",
    "\n",
    "    h = hsv[0]\n",
    "    s = hsv[1]\n",
    "    v = hsv[2]\n",
    "\n",
    "    #if s == 0.0: return v, v, v\n",
    "    i = (h*6.0).astype(int)\n",
    "    f = (h*6.0) - i\n",
    "    p = v*(1.0 - s)\n",
    "    q = v*(1.0 - s*f)\n",
    "    t = v*(1.0 - s*(1.0-f))\n",
    "\n",
    "    r = i.choose( v, q, p, p, t, v )\n",
    "    g = i.choose( t, v, v, q, p, p )\n",
    "    b = i.choose( p, p, t, v, v, q )\n",
    "\n",
    "    return (r,g,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shade_with_hillshade(r, g, b, z):\n",
    "    hsv = rgb_to_hsv(r, g, b)\n",
    "    z = (z * 256) / 200\n",
    "    z = (z * 4 + hsv[2]) / 5\n",
    "    hsv[2] = z\n",
    "    return hsv_to_rgb(hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render_with_hillshade(tiles):\n",
    "    landsat_tile = tiles[0]\n",
    "    hillshade = tiles[1].cells[0]\n",
    "    (r, g, b, alpha) = landsat_rgba(tiles[0])\n",
    "    (r, g, b) = shade_with_hillshade(r, g, b, hillshade)\n",
    "\n",
    "    rgba = np.dstack([r,g,b,alpha]).astype('uint8')\n",
    "    return Image.fromarray(rgba, mode='RGBA')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in M.layers:\n",
    "    M.remove_layer(x)\n",
    "\n",
    "tms_server = gps.TMS.build([landsat_pyramid, hillshade_pyramid], display=render_with_hillshade)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"landsat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in NLCD and rio_color\n",
    "\n",
    "Here we bring in NLCD, and replace certain land cover values with original\n",
    "landsat RGB values.\n",
    "\n",
    "We also use Mapbox's `rio_color` library to perform contrast and saturation adjustment as well as gamma correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlcd_layer = gps.query(\"s3://datahub-catalogs-us-east-1\", \n",
    "                      \"nlcd-zoomed-256\", \n",
    "                      layer_zoom=13,\n",
    "                      query_geom=landsat_layer.layer_metadata.extent.to_polygon,\n",
    "                      num_partitions=100)\n",
    "\n",
    "labels = { 0: 'NoData',\n",
    "          11: 'Open Water',\n",
    "          12: 'Perennial Ice/Snow',\n",
    "          21: 'Developed, Open Space',\n",
    "          22: 'Developed, Low Intensity',\n",
    "          23: 'Developed, Medium Intensity',\n",
    "          24: 'Developed High Intensity',\n",
    "          31: 'Barren Land (Rock/Sand/Clay)',\n",
    "          41: 'Deciduous Forest',\n",
    "          42: 'Evergreen Forest ',\n",
    "          43: 'Mixed Forest',\n",
    "          52: 'Shrub/Scrub',\n",
    "          71: 'Grassland/Herbaceous',\n",
    "          81: 'Pasture/Hay',\n",
    "          82: 'Cultivated Crops',\n",
    "          90: 'Woody Wetlands',\n",
    "          95: 'Emergent Herbaceous Wetlands'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlcd_pyramid = nlcd_layer.repartition(100).pyramid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_classes(target_rgb, source_rgb, nlcd):\n",
    "    r1, g1, b1 = target_rgb\n",
    "    r2, g2, b2 = source_rgb\n",
    "    \n",
    "    # Copy original values in developed land\n",
    "    developed_land = (nlcd >= 22) & (nlcd <= 24)\n",
    "    \n",
    "    np.copyto(r1, r2, where=developed_land)\n",
    "    np.copyto(g1, g2, where=developed_land)\n",
    "    np.copyto(b1, b2, where=developed_land)\n",
    "    \n",
    "    return np.array([r1, g1, b1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render3(tiles):\n",
    "    landsat_tile = tiles[0]\n",
    "    hillshade = tiles[1].cells[0]\n",
    "    nlcd = tiles[2].cells[0]\n",
    "\n",
    "    (r, g, b, alpha) = landsat_rgba(tiles[0])\n",
    "    (h_r, h_g, h_b) = shade_with_hillshade(r, g, b, hillshade)\n",
    "    rgb = replace_classes(np.array([h_r, h_g, h_b]), \n",
    "                          np.array([r, g, b]),\n",
    "                          nlcd)\n",
    "    ### rio_color color correction\n",
    "    \n",
    "    # Move rgb values to 0.0 - 1.0 space\n",
    "    rgb = rgb.astype(float)\n",
    "    rgb[rgb < 0] = 0\n",
    "    rgb /= 256.0\n",
    "\n",
    "    # Adjust gamma and sigmoidal contrast\n",
    "    rgb = gamma(rgb, 1.2)\n",
    "    rgb = sigmoidal(rgb, 3, 0.45)\n",
    "\n",
    "    # Saturate water\n",
    "    np.copyto(rgb,  saturation(rgb, 2), where=nlcd == 11)\n",
    "    \n",
    "    # Convert back to byte space\n",
    "    rgb *= 256\n",
    "\n",
    "    # Set water opacity to 80%\n",
    "    np.copyto(alpha, (alpha * 0.8).astype('int32'), where=nlcd == 11)\n",
    "    \n",
    "    rgba = np.dstack([rgb[0],rgb[1],rgb[2],alpha]).astype('uint8')\n",
    "    return Image.fromarray(rgba, mode='RGBA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in M.layers:\n",
    "    M.remove_layer(x)\n",
    "    \n",
    "tms_server = gps.TMS.build([landsat_pyramid, hillshade_pyramid, nlcd_pyramid], display=render3)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"landsat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add in NDVI\n",
    "\n",
    "Finally, we're going to use NDVI to make choices about how we color correct ceratin pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        c = np.true_divide(a, b)\n",
    "        c[c == np.inf] = 0\n",
    "        c = np.nan_to_num(c)\n",
    "        return c\n",
    "\n",
    "\n",
    "def compute_ndvi(tile):\n",
    "    cells = tile.cells.astype(float)\n",
    "    red = cells[2]\n",
    "    ir = cells[3]\n",
    "    return  safe_divide((ir - red), (ir + red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render4(tiles):\n",
    "    landsat_tile = tiles[0]\n",
    "    hillshade = tiles[1].cells[0]\n",
    "    nlcd = tiles[2].cells[0]\n",
    "    ndvi = compute_ndvi(landsat_tile)\n",
    "    \n",
    "    (l_r, l_g, l_b, alpha) = landsat_rgba(tiles[0])\n",
    "    (h_r, h_g, h_b) = shade_with_hillshade(l_r, l_g, l_b, hillshade)\n",
    "\n",
    "    ##### rio_color color correction\n",
    "    \n",
    "    # Move rgb values to 0.0 - 1.0 space\n",
    "    rgb = np.array([h_r, h_g, h_b])\n",
    "    rgb = rgb.astype(float)\n",
    "    rgb[rgb < 0] = 0\n",
    "    rgb /= 256.0\n",
    "\n",
    "    # Adjust gamma and sigmoidal contrast\n",
    "    rgb = gamma(rgb, 1.2)\n",
    "    rgb = sigmoidal(rgb, 3, 0.45)\n",
    "    \n",
    "    # Saturate water\n",
    "    np.copyto(rgb,  saturation(rgb, 2), where=nlcd == 11)\n",
    "    \n",
    "    g = rgb[1]\n",
    "    # Higher gamma for NDVI\n",
    "    np.copyto(g, gamma(g, 1.1), where=ndvi > 0.45)\n",
    "    \n",
    "    # Higher contrast for NDVI\n",
    "    np.copyto(g, sigmoidal(g, 7, 0.42), where=ndvi > 0.45)\n",
    "    \n",
    "    rgb = np.array([rgb[0], g, rgb[2]])\n",
    "    \n",
    "    # Desaturate high NDVI\n",
    "    np.copyto(rgb, saturation(rgb, 0.7), where=ndvi > 0.45)\n",
    "    \n",
    "    ## Saturate the whole image\n",
    "    rgb = saturation(rgb, 1.2)\n",
    "    \n",
    "    # Convert back to byte space\n",
    "    rgb *= 256\n",
    "    \n",
    "    ###### rio color correct the original landsat rgb values\n",
    "\n",
    "    # Move rgb values to 0.0 - 1.0 space\n",
    "    lrgb = np.array([l_r, l_g, l_b])\n",
    "    lrgb = lrgb.astype(float)\n",
    "    lrgb[lrgb < 0] = 0\n",
    "    lrgb /= 256.0\n",
    "\n",
    "    # Adjust gamma and sigmoidal contrast\n",
    "    lrgb = gamma(lrgb, 1.2)\n",
    "    lrgb = sigmoidal(lrgb, 3, 0.45)\n",
    "    lrgb = saturation(lrgb, 0.1)\n",
    "\n",
    "    # Convert back to byte space\n",
    "    lrgb *= 256\n",
    "    \n",
    "    rgb = replace_classes(rgb, \n",
    "                          lrgb,\n",
    "                          nlcd)\n",
    "\n",
    "    # Set water opacity to 80%\n",
    "    np.copyto(alpha, (alpha * 0.8).astype('int32'), where=nlcd == 11)\n",
    "    \n",
    "    rgba = np.dstack([rgb[0],rgb[1],rgb[2],alpha]).astype('uint8')\n",
    "    return Image.fromarray(rgba, mode='RGBA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in M.layers:\n",
    "    M.remove_layer(x)\n",
    "\n",
    "tms_server = gps.TMS.build([landsat_pyramid, hillshade_pyramid, nlcd_pyramid], display=render4)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"landsat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see what you can do!\n",
    "\n",
    "All of the parameters can be adjusted to create new images. You could add the Crop Data Layer to further modify the image. Play around with the code and see what kind of interesting art you can create with maps!\n",
    "\n",
    "If you hit on something interesting, please tweet a screenshot of it out with\n",
    "the hashtags __#foss4g__ and __#geopyspark__!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoNotebook + GeoPySpark",
   "language": "python",
   "name": "geonotebook3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
