{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Processing a Landsat Scene into Art\n",
    "\n",
    "In this exercise, we will process a landsat scene directly from the raw GeoTiff, hosted on AWS. This is different then the Landsat Scene data we've been interacting with in the earlier exercises, which had been pre-processed by GeoTrellis into a GeoTrellis Layer.\n",
    "\n",
    "After we grab process the landsat scene, we'll combine it with [NED](https://lta.cr.usgs.gov/NED) and [NLCD](https://catalog.data.gov/dataset/national-land-cover-database-nlcd-land-cover-collection) data and adjust coloring via [rio_color](https://github.com/mapbox/rio-color/tree/master/rio_color) to make a cool looking map layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import osr\n",
    "import rasterio.warp\n",
    "import geopyspark as gps\n",
    "import numpy as np\n",
    "import csv, os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import math\n",
    "from PIL import Image\n",
    "import pyproj\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely.ops import transform\n",
    "from functools import partial\n",
    "import urllib.request, json\n",
    "import dateutil.parser\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark import SparkContext\n",
    "from geonotebook.wrappers import TMSRasterData, GeoJsonData\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "\n",
    "from rasterfoundry.api import API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up our spark context\n",
    "conf = gps.geopyspark_conf(appName=\"Landsat\") \\\n",
    "          .setMaster(\"local[*]\") \\\n",
    "          .set(key='spark.ui.enabled', value='true') \\\n",
    "          .set(key=\"spark.driver.memory\", value=\"8G\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\"/home/hadoop/notebooks/exercises/exercise4/annotation-tool.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the GeoJson for our Area of Interest\n",
    "\n",
    "We can use the annotation tool in GeoNotebook to grab an extent that we are interested in. The location of the tool is in the toolbar, highlighted here:\n",
    "![Annotation tool](files/annotation-tool.png)\n",
    "\n",
    "Draw a small bounding box in an area you'd like to processes a landsat scene for.\n",
    "\n",
    "We can then use GeoNotebook to grab the annotation and get the polygon it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = M.layers.annotation.rectangles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = aoi.centroid\n",
    "M.set_center(p.x, p.y, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Raster Foundry to find Landsast 8 scenes\n",
    "\n",
    "Here we set up a client to read from the [Raster Foundry](https://www.rasterfoundry.com/) API any scenes that match our area of interest over a time in 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = API(refresh_token='47MAq91iWa6xlbqEW5d6uustkslFI75ZaawBdzW2gVoZ0')\n",
    "landsat_8 = client.get_datasources(name='Landsat 8').results[0]\n",
    "\n",
    "min_datetime = datetime(2017, 1, 1).isoformat() + 'Z'\n",
    "max_datetime = datetime(2017, 12, 1).isoformat() + 'Z'\n",
    "bounds = ','.join(map(lambda x: str(x), aoi.bounds))\n",
    "\n",
    "filters = dict(pageSize=250, datasource=[landsat_8.id],\n",
    "                   minAcquisitionDatetime=min_datetime,\n",
    "                   maxAcquisitionDatetime=max_datetime,\n",
    "                   bbox=bounds,\n",
    "                   maxCloudCover=10)\n",
    "\n",
    "# Initial conditions\n",
    "has_next = True\n",
    "page = 0\n",
    "results = []\n",
    "\n",
    "while has_next:\n",
    "    print(\"Processing Page {}\".format(page))\n",
    "    scenes = client.get_scenes(page=page, **filters)\n",
    "    if page == 0:\n",
    "        print('{} scenes total match query'.format(scenes.count))\n",
    "    for scene in scenes.results:\n",
    "        results.append(scene)\n",
    "    page += 1\n",
    "    has_next = scenes.hasNext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking a scene\n",
    "\n",
    "We can use the thumbnail information on the results to browse the scenes and select the one we want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_image(img, name):\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(6, 4)\n",
    "\n",
    "    a = fig.add_subplot(1, 2, 1)\n",
    "    a.set_title(name)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def get_thumbnail(scene, size='SMALL'):\n",
    "    url = list(filter(lambda t: t.thumbnailSize == size, scene.thumbnails))[0].url\n",
    "    file = io.BytesIO(urllib.request.urlopen(url).read())\n",
    "    return Image.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "for i, scene in enumerate(results):\n",
    "    plot_image(get_thumbnail(scene), \"Scene {}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = results[5]\n",
    "get_thumbnail(scene, size='LARGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the RDD of Scene information\n",
    "\n",
    "This bit of code grabs the relevant information from the Raster Foundry results for our scene, and parallizes that collection of information into an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convenience tuple to store Scene information for GeoPySpark\n",
    "SceneRow = namedtuple('SceneRow', 'date, scene_id, band, uri')\n",
    "\n",
    "desired_bands = {\n",
    "    # 'coastal aerosol - 1': 0,\n",
    "    'blue - 2': 1,\n",
    "    'green - 3': 2,\n",
    "    'red - 4': 3,\n",
    "    'near infrared - 5': 4,\n",
    "    # 'swir - 6': 5,\n",
    "    # 'swir - 7': 6,\n",
    "    # 'panchromatic - 8': 7,\n",
    "    # 'cirrus - 9': 8,\n",
    "    # 'thermal infrared - 10': 9,\n",
    "    # 'thermal infrared - 11': 10,\n",
    "    #'QA': 11\n",
    "}\n",
    "\n",
    "def get_desired_bands(scene):\n",
    "    \"\"\"Convenience function to process desired bands for GeoPySpark\n",
    "\n",
    "    Args:\n",
    "        scene:\n",
    "\n",
    "    Returns:\n",
    "        List[SceneRow]\n",
    "    \"\"\"\n",
    "    acquisition_date = scene.filterFields.acquisitionDate\n",
    "    landsat_8_rows = []\n",
    "    for image in scene.images:\n",
    "        uri = image.sourceUri\n",
    "        band_name = image.bands[0].name\n",
    "        band_num = desired_bands.get(band_name)\n",
    "        if band_num:\n",
    "            row = SceneRow(acquisition_date, scene.name, band_num, uri)\n",
    "            landsat_8_rows.append(row)\n",
    "\n",
    "    return landsat_8_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scene_info = sc.parallelize(get_desired_bands(scene)).repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metadata(row):\n",
    "    with rasterio.open(row.uri) as dataset:\n",
    "        bounds = dataset.bounds\n",
    "        height = dataset.height\n",
    "        width = dataset.width\n",
    "        crs = dataset.get_crs()\n",
    "        srs = osr.SpatialReference()\n",
    "        srs.ImportFromWkt(crs.wkt)\n",
    "        proj4 = srs.ExportToProj4()\n",
    "        tile_cols = math.floor((width - 1) / 512) * 512\n",
    "        tile_rows = math.floor((height - 1) / 512) * 512\n",
    "        ws = [((x, x + 512), (y, y + 512)) for x in range(0,tile_cols, 512) \\\n",
    "                                          for y in range(0, tile_rows, 512)]\n",
    "\n",
    "    def windows(row, ws):\n",
    "        for w in ws:\n",
    "            ((row_start, row_stop), (col_start, col_stop)) = w\n",
    "\n",
    "            left  = bounds.left + (bounds.right - bounds.left)*(float(col_start)/width)\n",
    "            right = bounds.left + (bounds.right - bounds.left)*(float(col_stop)/ width)\n",
    "            bottom = bounds.top + (bounds.bottom - bounds.top)*(float(row_stop)/height)\n",
    "            top = bounds.top + (bounds.bottom - bounds.top)*(float(row_start)/height)\n",
    "            extent = gps.Extent(left,bottom,right,top)\n",
    "            instant = datetime.strptime(row.date, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "            projected_extent = gps.TemporalProjectedExtent(extent=extent, \n",
    "                                                            instant=instant, \n",
    "                                                            proj4=proj4)\n",
    "            window_info = { 'scene_id': row.scene_id, \n",
    "                            'band': row.band, \n",
    "                            'uri': row.uri,\n",
    "                            'window': w,\n",
    "                            'projected_extent': projected_extent,\n",
    "                            'tile_key': (row_start, col_start) }\n",
    "\n",
    "            yield window_info\n",
    "    \n",
    "    return [i for i in windows(row, ws)]\n",
    "\n",
    "scene_window_metadata = scene_info.flatMap(get_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(line):\n",
    "    \n",
    "    new_line = line.copy()\n",
    "\n",
    "    with rasterio.open(line['uri']) as dataset:\n",
    "        new_line['data'] = dataset.read(1, window=line['window'])\n",
    "        new_line.pop('window')\n",
    "        new_line.pop('uri')\n",
    "    \n",
    "    return new_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scene_band_tiles = scene_window_metadata.repartition(500).map(get_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_band_tiles = \\\n",
    "  scene_band_tiles.groupBy(lambda line: (line['scene_id'], line['tile_key']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_tiles(grouped):\n",
    "    lines = list(grouped[1])\n",
    "    projected_extent = lines[0]['projected_extent']\n",
    "    try:\n",
    "        array = np.array([l['data'] for l in sorted(lines, key=lambda l: int(l['band']))])\n",
    "        if array.dtype == 'object':\n",
    "            bandshapes = [str(l['data'].shape) for l in sorted(lines, key=lambda l: l['band'])]\n",
    "            raise Exception(\"{}\".format('\\n'.join(bandshapes)))\n",
    "    except:\n",
    "        bandshapes = [\"{} - {}\".format(l['band'], l['data'].shape) for l in sorted(lines, key=lambda l: l['band'])]\n",
    "        raise Exception(\"ER {}\".format('\\n'.join(bandshapes)))\n",
    "    tile = gps.Tile.from_numpy_array(array, no_data_value=0.0)\n",
    "    return (projected_extent, tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_tiles = grouped_band_tiles.map(make_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raster_layer = gps.RasterLayer.from_numpy_rdd(gps.LayerType.SPACETIME, combined_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tiled_raster_layer = raster_layer.tile_to_layout(layout = gps.GlobalLayout(), target_crs=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "landsat_layer = tiled_raster_layer.to_spatial_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "landsat_pyramid = landsat_layer \\\n",
    "                    .repartition(100) \\\n",
    "                    .pyramid(resample_method=gps.ResampleMethod.BILINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If we wanted to write the pyramid, we could do so like this:\n",
    "\"\"\"\n",
    "for layer in sorted(pyramid.levels.values(), key=lambda l: -l.zoom_level):\n",
    "    gps.write(\"s3://some/catalog\", \"my-landsat-image\", layer, time_unit=gps.TimeUnit.DAYS)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def landsat_rgba(tile):\n",
    "    cells = tile.cells\n",
    "    # Color correct - use magic numbers\n",
    "    magic_min, magic_max = 4000, 15176\n",
    "    norm_range = magic_max - magic_min\n",
    "    cells = cells.astype('int32')\n",
    "    # Clamp cells\n",
    "    cells[(cells != 0) & (cells < magic_min)] = magic_min\n",
    "    cells[(cells != 0) & (cells > magic_max)] = magic_max\n",
    "    colored = ((cells - magic_min) * 255) / norm_range\n",
    "    r, g, b = (colored[2], colored[1], colored[0])\n",
    "    alpha = np.full(r.shape, 255)\n",
    "    alpha[(cells[0] == tile.no_data_value) & \\\n",
    "          (cells[1] == tile.no_data_value) & \\\n",
    "          (cells[2] == tile.no_data_value)] = 0\n",
    "    return (r, g, b, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render_image(tile):\n",
    "    (r, g, b, alpha) = landsat_rgba(tile)\n",
    "    rgba = np.dstack([r,g,b, alpha]).astype('uint8')\n",
    "    return Image.fromarray(rgba, mode='RGBA')\n",
    "\n",
    "for x in M.layers:\n",
    "    M.remove_layer(x)\n",
    "\n",
    "tms_server = gps.TMS.build(landsat_pyramid, display=render_image)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"landsat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Add in hillshade from National Elevation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elevation_layer = gps.query(\"s3://azavea-datahub/catalog\", \n",
    "                            \"us-ned-tms-epsg3857\", \n",
    "                            layer_zoom=13,\n",
    "                            query_geom=landsat_layer.layer_metadata.extent.to_polygon,\n",
    "                            num_partitions=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hillshade = gps.hillshade(elevation_layer, band=0, azimuth=99.0, altitude=33.0, z_factor=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hillshade_pyramid = hillshade.repartition(100).pyramid(resample_method=gps.ResampleMethod.BILINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See http://fwarmerdam.blogspot.com/2010/01/hsvmergepy.html\n",
    "# =============================================================================\n",
    "# rgb_to_hsv()\n",
    "#\n",
    "# rgb comes in as [r,g,b] with values in the range [0,255].  The returned\n",
    "# hsv values will be with hue and saturation in the range [0,1] and value\n",
    "# in the range [0,255]\n",
    "#\n",
    "def rgb_to_hsv( r,g,b ):\n",
    "\n",
    "    maxc = np.maximum(r,np.maximum(g,b))\n",
    "    minc = np.minimum(r,np.minimum(g,b))\n",
    "\n",
    "    v = maxc\n",
    "\n",
    "    minc_eq_maxc = np.equal(minc,maxc)\n",
    "\n",
    "    # compute the difference, but reset zeros to ones to avoid divide by zeros later.\n",
    "    ones = np.ones((r.shape[0],r.shape[1]))\n",
    "    maxc_minus_minc = np.choose( minc_eq_maxc, (maxc-minc,ones) )\n",
    "\n",
    "    s = (maxc-minc) / np.maximum(ones,maxc)\n",
    "    rc = (maxc-r) / maxc_minus_minc\n",
    "    gc = (maxc-g) / maxc_minus_minc\n",
    "    bc = (maxc-b) / maxc_minus_minc\n",
    "\n",
    "    maxc_is_r = np.equal(maxc,r)\n",
    "    maxc_is_g = np.equal(maxc,g)\n",
    "    maxc_is_b = np.equal(maxc,b)\n",
    "\n",
    "    h = np.zeros((r.shape[0],r.shape[1]))\n",
    "    h = np.choose( maxc_is_b, (h,4.0+gc-rc) )\n",
    "    h = np.choose( maxc_is_g, (h,2.0+rc-bc) )\n",
    "    h = np.choose( maxc_is_r, (h,bc-gc) )\n",
    "\n",
    "    h = np.mod(h/6.0,1.0)\n",
    "\n",
    "    hsv = np.asarray([h,s,v])\n",
    "\n",
    "    return hsv\n",
    "\n",
    "# =============================================================================\n",
    "# hsv_to_rgb()\n",
    "#\n",
    "# hsv comes in as [h,s,v] with hue and saturation in the range [0,1],\n",
    "# but value in the range [0,255].\n",
    "\n",
    "def hsv_to_rgb( hsv ):\n",
    "\n",
    "    h = hsv[0]\n",
    "    s = hsv[1]\n",
    "    v = hsv[2]\n",
    "\n",
    "    #if s == 0.0: return v, v, v\n",
    "    i = (h*6.0).astype(int)\n",
    "    f = (h*6.0) - i\n",
    "    p = v*(1.0 - s)\n",
    "    q = v*(1.0 - s*f)\n",
    "    t = v*(1.0 - s*(1.0-f))\n",
    "\n",
    "    r = i.choose( v, q, p, p, t, v )\n",
    "    g = i.choose( t, v, v, q, p, p )\n",
    "    b = i.choose( p, p, t, v, v, q )\n",
    "\n",
    "    return (r,g,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render_with_hillshade(tiles):\n",
    "    landsat_tile = tiles[0]\n",
    "    hillshade_tile = tiles[1]\n",
    "    (r, g, b, alpha) = landsat_rgba(tiles[0])\n",
    "    rgba = np.dstack([r,g,b, alpha]).astype('uint8')\n",
    "    hsv = rgb_to_hsv(r, g, b)\n",
    "    z = hillshade_tile.cells[0]\n",
    "    z = (z * 256) / 200\n",
    "    z = (z * 2 + hsv[2]) / 3\n",
    "    hsv[2] = z\n",
    "    (r, g, b) = hsv_to_rgb(hsv)\n",
    "\n",
    "    rgba = np.dstack([r,g,b,alpha]).astype('uint8')\n",
    "    return Image.fromarray(rgba, mode='RGBA')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in M.layers:\n",
    "    M.remove_layer(x)\n",
    "\n",
    "tms_server = gps.TMS.build([landsat_pyramid, hillshade_pyramid], display=render_with_hillshade)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"landsat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add in NLCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlcd_layer = gps.query(\"s3://datahub-catalogs-us-east-1\", \n",
    "                      \"nlcd-zoomed-256\", \n",
    "                      layer_zoom=13,\n",
    "                      query_geom=landsat_layer.layer_metadata.extent.to_polygon,\n",
    "                      num_partitions=100)\n",
    "\n",
    "labels = { 0: 'NoData',\n",
    "          11: 'Open Water',\n",
    "          12: 'Perennial Ice/Snow',\n",
    "          21: 'Developed, Open Space',\n",
    "          22: 'Developed, Low Intensity',\n",
    "          23: 'Developed, Medium Intensity',\n",
    "          24: 'Developed High Intensity',\n",
    "          31: 'Barren Land (Rock/Sand/Clay)',\n",
    "          41: 'Deciduous Forest',\n",
    "          42: 'Evergreen Forest ',\n",
    "          43: 'Mixed Forest',\n",
    "          52: 'Shrub/Scrub',\n",
    "          71: 'Grassland/Herbaceous',\n",
    "          81: 'Pasture/Hay',\n",
    "          82: 'Cultivated Crops',\n",
    "          90: 'Woody Wetlands',\n",
    "          95: 'Emergent Herbaceous Wetlands'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlcd_pyramid = nlcd_layer.repartition(100).pyramid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render3(tiles):\n",
    "    landsat_tile = tiles[0]\n",
    "    hillshade_tile = tiles[1]\n",
    "    nlcd_tile = tiles[2]\n",
    "    (r, g, b, alpha) = landsat_rgba(tiles[0])\n",
    "    #rgba = np.dstack([r,g,b, alpha]).astype('uint8')\n",
    "    #return Image.fromarray(rgba, mode='RGBA')\n",
    "    hsv = rgb_to_hsv(r, g, b)\n",
    "    z = hillshade_tile.cells[0]\n",
    "    z = (z * 256) / 200\n",
    "    z = (z * 3 + hsv[2]) / 4\n",
    "    hsv[2] = z\n",
    "    (h_r, h_g, h_b) = hsv_to_rgb(hsv)\n",
    "    \n",
    "    nlcd = nlcd_tile.cells[0]\n",
    "    # Copy original values in developed land\n",
    "    developed_land = (nlcd >= 22) & (nlcd <= 23)\n",
    "    np.copyto(h_r, r, where=developed_land)\n",
    "    np.copyto(h_g, r, where=developed_land)\n",
    "    np.copyto(h_b, r, where=developed_land)\n",
    "    \n",
    "    ### rio_color color correction\n",
    "    \n",
    "    # Move rgb values to 0.0 - 1.0 space\n",
    "    rgb = np.array([h_r, h_g, h_b])\n",
    "    rgb = rgb.astype(float)\n",
    "    rgb[rgb < 0] = 0\n",
    "    rgb /= 256.0\n",
    "\n",
    "    # Adjust gamma and sigmoidal contrast\n",
    "    rgb = gamma(rgb, 1.2)\n",
    "    rgb = sigmoidal(rgb, 3, 0.45)\n",
    "\n",
    "    # Saturate water\n",
    "    np.copyto(rgb,  saturation(rgb, 2), where=nlcd == 11)\n",
    "    \n",
    "    # Convert back to byte space\n",
    "    rgb *= 256\n",
    "\n",
    "    # Set water opacity to 80%\n",
    "    np.copyto(alpha, (alpha * 0.8).astype('int64'), where=nlcd == 11)\n",
    "    \n",
    "    rgba = np.dstack([rgb[0],rgb[1],rgb[2],alpha]).astype('uint8')\n",
    "    return Image.fromarray(rgba, mode='RGBA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in M.layers:\n",
    "    M.remove_layer(x)\n",
    "    \n",
    "tms_server = gps.TMS.build([landsat_pyramid, hillshade_pyramid, nlcd_pyramid], display=render3)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"landsat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add in NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        c = np.true_divide(a, b)\n",
    "        c[c == np.inf] = 0\n",
    "        c = np.nan_to_num(c)\n",
    "        return c\n",
    "\n",
    "\n",
    "def compute_ndvi(tile):\n",
    "    cells = tile.cells.astype(float)\n",
    "    red = cells[2]\n",
    "    ir = cells[3]\n",
    "    return  safe_divide((ir - red), (ir + red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rio_color.operations import gamma, sigmoidal, saturation\n",
    "\n",
    "def render3(tiles):\n",
    "    landsat_tile = tiles[0]\n",
    "    hillshade_tile = tiles[1]\n",
    "    nlcd_tile = tiles[2]\n",
    "    ndvi = compute_ndvi(landsat_tile)\n",
    "    nlcd = nlcd_tile.cells[0]\n",
    "\n",
    "    (r, g, b, alpha) = landsat_rgba(tiles[0])\n",
    " \n",
    "    hsv = rgb_to_hsv(r, g, b)\n",
    "    z = hillshade_tile.cells[0]\n",
    "    z = (z * 256) / 200\n",
    "    z = (z * 3 + hsv[2]) / 4\n",
    "    hsv[2] = z\n",
    "    (h_r, h_g, h_b) = hsv_to_rgb(hsv)\n",
    "    \n",
    "   \n",
    "    # Copy original values in developed land\n",
    "    developed_land = (nlcd >= 22) & (nlcd <= 23)\n",
    "    np.copyto(h_r, r, where=developed_land)\n",
    "    np.copyto(h_g, r, where=developed_land)\n",
    "    np.copyto(h_b, r, where=developed_land)\n",
    "    \n",
    "    ### rio_color color correction\n",
    "    \n",
    "    # Move rgb values to 0.0 - 1.0 space\n",
    "    rgb = np.array([h_r, h_g, h_b])\n",
    "    rgb = rgb.astype(float)\n",
    "    rgb[rgb < 0] = 0\n",
    "    rgb /= 256.0\n",
    "\n",
    "    # Adjust gamma and sigmoidal contrast\n",
    "    rgb = gamma(rgb, 1.2)\n",
    "    rgb = sigmoidal(rgb, 3, 0.45)\n",
    "    \n",
    "    # Saturate water\n",
    "    np.copyto(rgb,  saturation(rgb, 2), where=nlcd == 11)\n",
    "    \n",
    "    g = rgb[1]\n",
    "    # Higher brightness for NDVI\n",
    "    np.copyto(g, gamma(g, 1.2), where=ndvi > 0.3)\n",
    "    np.copyto(g, gamma(g, 1.4), where=ndvi > 0.6)\n",
    "    np.copyto(g, gamma(g, 1.7), where=ndvi > 0.9)\n",
    "    \n",
    "    # Higher contrast for NDVI\n",
    "    np.copyto(g, sigmoidal(g, 3, 0.45), where=ndvi > 0.3)\n",
    "    np.copyto(g, sigmoidal(g, 4, 0.4), where=ndvi > 0.6)\n",
    "    np.copyto(g, sigmoidal(g, 5, 0.35), where=ndvi > 0.9)\n",
    "    \n",
    "    rgb = np.array([rgb[0], g, rgb[2]])\n",
    "    \n",
    "    # Saturate high NDVI\n",
    "    np.copyto(rgb, saturation(rgb, 0.5), where=ndvi > 0.1)\n",
    "    np.copyto(rgb, saturation(rgb, 0.8), where=ndvi > 0.2)\n",
    "    np.copyto(rgb, saturation(rgb, 1.1), where=ndvi > 0.45)\n",
    "    \n",
    "    # Convert back to byte space\n",
    "    rgb *= 256\n",
    "\n",
    "    # Set water opacity to 80%\n",
    "    np.copyto(alpha, (alpha * 0.8).astype('int64'), where=nlcd == 11)\n",
    "    \n",
    "    rgba = np.dstack([rgb[0],rgb[1],rgb[2],alpha]).astype('uint8')\n",
    "    return Image.fromarray(rgba, mode='RGBA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in M.layers:\n",
    "    M.remove_layer(x)\n",
    "\n",
    "tms_server = gps.TMS.build([landsat_pyramid, hillshade_pyramid, nlcd_pyramid], display=render3)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"landsat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoNotebook + GeoPySpark",
   "language": "python",
   "name": "geonotebook3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
