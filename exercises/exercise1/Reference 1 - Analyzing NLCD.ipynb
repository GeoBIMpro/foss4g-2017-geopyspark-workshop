{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Land Cover data\n",
    "\n",
    "This notebook performs an analysis of [NLCD](https://catalog.data.gov/dataset/national-land-cover-database-nlcd-land-cover-collection)\n",
    "data over a state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopyspark as gps\n",
    "from pyspark import SparkContext\n",
    "from shapely.geometry import mapping, shape, asShape, MultiPoint, MultiLineString\n",
    "from geonotebook.wrappers import TMSRasterData, GeoJsonData\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from functools import partial\n",
    "import os, urllib.request, json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup: State data and Spark initialization\n",
    "\n",
    "The next 2 cells grab the shapes for our state and start up the spark context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab data for Nevada\n",
    "state_name, county_name = \"NJ\", \"Hunterdon\"\n",
    "def get_state_shapes(state, county):\n",
    "    project = partial(\n",
    "        pyproj.transform,\n",
    "        pyproj.Proj(init='epsg:4326'),\n",
    "        pyproj.Proj(init='epsg:3857'))\n",
    "\n",
    "    state_url = \"https://raw.githubusercontent.com/johan/world.geo.json/master/countries/USA/{}.geo.json\".format(state)\n",
    "    county_url = \"https://raw.githubusercontent.com/johan/world.geo.json/master/countries/USA/{}/{}.geo.json\".format(state,county)\n",
    "    read_json = lambda url: json.loads(urllib.request.urlopen(url).read().decode(\"utf-8\"))\n",
    "    state_ll = shape(read_json(state_url)['features'][0]['geometry'])\n",
    "    state_wm = transform(project, state_ll)\n",
    "    county_ll = shape(read_json(county_url)['features'][0]['geometry'])\n",
    "    county_wm = transform(project, county_ll)\n",
    "    return (state_ll, state_wm, county_ll, county_wm)\n",
    "\n",
    "(state_ll, state_wm, county_ll, county_wm) = get_state_shapes(state_name, county_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up our spark context\n",
    "conf = gps.geopyspark_conf(appName=\"Landsat\") \\\n",
    "          .setMaster(\"local[*]\") \\\n",
    "          .set(key='spark.ui.enabled', value='true') \\\n",
    "          .set(key=\"spark.driver.memory\", value=\"8G\") \\\n",
    "          .set(\"spark.hadoop.yarn.timeline-service.enabled\", False)\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View NLCD from GeoTrellis Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlcd_layer_name = \"nlcd-zoomed-256\"\n",
    "nlcd_color_map = gps.ColorMap.nlcd_colormap()\n",
    "tms_server = gps.TMS.build((\"s3://datahub-catalogs-us-east-1\", nlcd_layer_name), \n",
    "                           display=nlcd_color_map)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"nlcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = state_ll.centroid\n",
    "M.set_center(p.x, p.y, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read State NLCD Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer = gps.query(\"s3://datahub-catalogs-us-east-1\", \n",
    "                      nlcd_layer_name, \n",
    "                      layer_zoom=13, \n",
    "                      query_geom=state_wm,\n",
    "                      num_partitions=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now grab the min and max of our data. \n",
    "This is a spark \"action\", which executes the Directed Acyclic Graph\n",
    "of operations represented by the RDD that is represented by the layer,\n",
    "and returns values to the driver program and through to our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.get_min_max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Map Algebra\n",
    "\n",
    "We can do simple map algebra operations, such as addition, \n",
    "between our layer and a scalar, or between it and another layer.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(layer + 10).get_min_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(layer + (layer * 0.1)).get_min_max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyramiding and viewing our layer on the map\n",
    "\n",
    "Here we pyramid and set up a TMS server for our layer.\n",
    "Notice we call `repartition` before pyramid; this is because\n",
    "setting a partitioner on our layer makes key lookups more efficient,\n",
    "which is how individual tiles are pulled out and served by the TMS server.\n",
    "\n",
    "To render our layer, we are using a ColorMap built into GeoPySpark that maps\n",
    "NLCD values to their appropriate colors according to the [legend supplied by USGS](https://www.mrlc.gov/nlcd06_leg.php)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyramid = layer.repartition(100).pyramid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tms_server = gps.TMS.build(pyramid, \n",
    "                           display=gps.ColorMap.nlcd_colormap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in M.layers:\n",
    "    M.remove_layer(l)\n",
    "    \n",
    "M.add_layer(TMSRasterData(tms_server), name=\"nlcd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking our layer\n",
    "\n",
    "You may notice that our layer does not exactly match our state boundary. We can verify this by placing our state on the map as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.add_layer(GeoJsonData(mapping(state_ll)), name=\"poly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the query we did does not mask by default; it retrieved us the tiles that intersect with our geometry, but there are cells of those intersecting tiles that will lie outside of the state.\n",
    "\n",
    "To get our data tight to our state boundary, we can mask our layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masked = layer.mask(geometries=state_wm)\n",
    "masked_pyramid = masked.repartition(100).cache().pyramid()\n",
    "tms_server = gps.TMS.build(masked_pyramid, \n",
    "                           display=gps.ColorMap.nlcd_colormap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in M.layers:\n",
    "    M.remove_layer(l)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"nlcd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most popular land types in our state.\n",
    "\n",
    "Here we find the categories of land cover that have the most amount of cells assigned to them in our state.\n",
    "\n",
    "The first step is to convert our masked layer to a numpy rdd. That way we can treat our tiles as a true PySpark RDD, where both the keys and values of the RDD are native python types. The type of the value will be a `gps.Tile`, which contains a `cells` field that holds a numpy array. That way we can use numpy directly to interact with the raster data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = masked.to_numpy_rdd()\n",
    "rdd.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we map over our tiles to get the counts of every category per tile, and then reduce over the RDD to aggregate the counts. This gives us the total counts per category over the entire state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(tile):\n",
    "    values, counts = np.unique(tile.cells.flatten(), return_counts=True)\n",
    "    d = {}\n",
    "    for v, c in zip(values, counts):\n",
    "        if v != -128: # Remove NoData\n",
    "            d[v] = c\n",
    "    return d\n",
    "\n",
    "def merge_counts(d1, d2):\n",
    "    d = {}\n",
    "    for k in set(d1.keys()).union(set(d2.keys())):\n",
    "        v = 0\n",
    "        if k in d1:\n",
    "            v += d1[k]\n",
    "        if k in d2:\n",
    "            v += d2[k]\n",
    "        d[k] = v\n",
    "    return d\n",
    "\n",
    "counts = rdd.map(lambda x: get_counts(x[1])).reduce(merge_counts)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reduce has returned us a python dictionary; we are no longer working with RDDs, and can operate on the data however we wish. For example, we can turn our data into a pandas dataframe and plot the values, creating a visualization that lets us easily see which land cover categories are most popular in our state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = { 0: 'NoData',\n",
    "          11: 'Open Water',\n",
    "          12: 'Perennial Ice/Snow',\n",
    "          21: 'Developed, Open Space',\n",
    "          22: 'Developed, Low Intensity',\n",
    "          23: 'Developed, Medium Intensity',\n",
    "          24: 'Developed High Intensity',\n",
    "          31: 'Barren Land (Rock/Sand/Clay)',\n",
    "          41: 'Deciduous Forest',\n",
    "          42: 'Evergreen Forest ',\n",
    "          43: 'Mixed Forest',\n",
    "          52: 'Shrub/Scrub',\n",
    "          71: 'Grassland/Herbaceous',\n",
    "          81: 'Pasture/Hay',\n",
    "          82: 'Cultivated Crops',\n",
    "          90: 'Woody Wetlands',\n",
    "          95: 'Emergent Herbaceous Wetlands'}\n",
    "named_counts = {}\n",
    "for k in counts:\n",
    "    named_counts[labels[k]] = counts[k]\n",
    "\n",
    "df = pd.DataFrame.from_dict(named_counts,  orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.plot.bar(legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the \"Cultivated Crops\" category on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cultivated_land_colormap = gps.ColorMap.build(breaks={82: 0x00FF00FF},\n",
    "                                              classification_strategy=gps.ClassificationStrategy.EXACT,\n",
    "                                              fallback=0x00000000)    \n",
    "tms_server = gps.TMS.build(masked_pyramid, \n",
    "                           display=cultivated_land_colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in M.layers:\n",
    "    M.remove_layer(l)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"nlcd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoNotebook + GeoPySpark",
   "language": "python",
   "name": "geonotebook3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
