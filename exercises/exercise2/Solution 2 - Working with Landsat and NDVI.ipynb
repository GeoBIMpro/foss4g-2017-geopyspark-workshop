{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Landsat 8 and NDVI\n",
    "\n",
    "In this exercise, we will be analyzing the Landsat 8 data. The layer\n",
    "we will be using is an ingested subset of the Landsat on AWS data, \n",
    "which contains data over 2016, over the continental US, and with\n",
    "30% or less cloud cover.\n",
    "\n",
    "There are 3 objectives in this exercise:\n",
    "\n",
    "- __Objective 1__: Cloud mask and mosaic images for your county and view it on the map.\n",
    "- __Objective 2__: Find the time in the layer that has the highest average NDVI.\n",
    "- __Objective 3__: View the NDVI over the county for that date (where data is available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopyspark as gps\n",
    "from pyspark import SparkContext\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from shapely.geometry import mapping, shape\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from functools import partial\n",
    "import urllib.request, json\n",
    "from geonotebook.wrappers import TMSRasterData\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup: State data and Spark initialization\n",
    "\n",
    "The next 2 cells grab the shapes for our state and start up the spark context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab data for New Mexico\n",
    "state_name, county_name = \"NM\", \"Colfax\"\n",
    "def get_state_shapes(state, county):\n",
    "    project = partial(\n",
    "        pyproj.transform,\n",
    "        pyproj.Proj(init='epsg:4326'),\n",
    "        pyproj.Proj(init='epsg:3857'))\n",
    "\n",
    "    state_url = \"https://raw.githubusercontent.com/johan/world.geo.json/master/countries/USA/{}.geo.json\".format(state)\n",
    "    county_url = \"https://raw.githubusercontent.com/johan/world.geo.json/master/countries/USA/{}/{}.geo.json\".format(state,county)\n",
    "    read_json = lambda url: json.loads(urllib.request.urlopen(url).read().decode(\"utf-8\"))\n",
    "    state_ll = shape(read_json(state_url)['features'][0]['geometry'])\n",
    "    state_wm = transform(project, state_ll)\n",
    "    county_ll = shape(read_json(county_url)['features'][0]['geometry'])\n",
    "    county_wm = transform(project, county_ll)\n",
    "    return (state_ll, state_wm, county_ll, county_wm)\n",
    "\n",
    "(state_ll, state_wm, county_ll, county_wm) = get_state_shapes(state_name, county_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up our spark context\n",
    "conf = gps.geopyspark_conf(appName=\"Exercise 1\") \\\n",
    "          .setMaster(\"local[*]\") \\\n",
    "          .set(key='spark.ui.enabled', value='true') \\\n",
    "          .set(key=\"spark.driver.memory\", value=\"8G\") \\\n",
    "          .set(\"spark.hadoop.yarn.timeline-service.enabled\", False)\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup: Band names and color ramp\n",
    "\n",
    "The ingested layers have the RGB, near infrared, and QA bands of landsat 8 data.\n",
    "This dict maps the band names to band index, for more readable code.\n",
    "\n",
    "We also define a color ramp for viewing NDVI data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bands = { \"Blue\": 0,\n",
    "          \"Green\": 1,\n",
    "          \"Red\": 2,\n",
    "          \"NIR\": 3,\n",
    "          \"QA\": 4 }\n",
    "ndvi_breaks_dict = {0.05:0xffffe5aa, 0.1:0xf7fcb9ff, 0.2:0xd9f0a3ff, 0.3:0xaddd8eff, 0.4:0x78c679ff, 0.5:0x41ab5dff, 0.6:0x238443ff, 0.7:0x006837ff, 1.0:0x004529ff}\n",
    "ndvi_color_map = gps.ColorMap.from_break_map(ndvi_breaks_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective 1: Cloud mask and mosaic images for your county and view it on the map.\n",
    "\n",
    "Query the layer for your county during the summer months (6 - 8). Mosaic the images together using the functions defined below. Show the mosaiced layer on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_clouds(tile):\n",
    "    # Use the Landsat QA band to mask out cloud values\n",
    "    qa = tile.cells[bands[\"QA\"]]\n",
    "    #cloud = np.bitwise_and(qa, 0x4000)\n",
    "    #cirrus = np.bitwise_and(qa, 0x2000)\n",
    "    cloud = np.right_shift(qa, 14)\n",
    "    result_bands = []\n",
    "    for band in tile.cells[:-1]:\n",
    "        band[cloud == 3] = 0\n",
    "        result_bands.append(band)\n",
    "    return gps.Tile.from_numpy_array(np.array(result_bands), no_data_value=0)\n",
    "\n",
    "def mosaic(tiles):\n",
    "    # Mosiac by taking the youngest pixel.\n",
    "    sorted_tiles = sorted(list(tiles), key=lambda x: x[0], reverse=True)\n",
    "    result = sorted_tiles[0][1].cells.copy()\n",
    "    no_data_value = sorted_tiles[0][1].no_data_value\n",
    "    for _, tile_to_merge in sorted_tiles[1:]:\n",
    "        cells_to_merge = tile_to_merge.cells\n",
    "        left_merge_condition = result[0] == no_data_value\n",
    "        right_merge_condition = cells_to_merge[0] != tile_to_merge.no_data_value\n",
    "        \n",
    "        # We want to merge in data that is not already set\n",
    "        # in the result (where all pixels are set to the no_data_value),\n",
    "        # and where the incoming pixel represents data\n",
    "        # (where any pixel does not equal the no_data_value)\n",
    "        for band_idx in range(1, result.shape[0] - 1):\n",
    "            left_merge_condition = left_merge_condition & \\\n",
    "                                   (result[band_idx] == no_data_value)\n",
    "            right_merge_condition = right_merge_condition | \\\n",
    "                                    (cells_to_merge[band_idx] != tile_to_merge.no_data_value)\n",
    "            \n",
    "        result_bands = []\n",
    "        for band_idx in range(0, result.shape[0]):\n",
    "            band = result[band_idx]\n",
    "            np.copyto(band, \n",
    "                      cells_to_merge[band_idx], \n",
    "                      where=(left_merge_condition) & \\\n",
    "                            (right_merge_condition))\n",
    "            result_bands.append(band)\n",
    "        result = np.array(result_bands)    \n",
    "\n",
    "    return gps.Tile.from_numpy_array(result, no_data_value=no_data_value)\n",
    "\n",
    "def render_image(tile):\n",
    "    cells = tile.cells\n",
    "    # Color correct - use magic numbers\n",
    "    magic_min, magic_max = 4000, 15176\n",
    "    norm_range = magic_max - magic_min\n",
    "    cells = cells.astype('int32')\n",
    "    # Clamp cells\n",
    "    cells[(cells != 0) & (cells < magic_min)] = magic_min\n",
    "    cells[(cells != 0) & (cells > magic_max)] = magic_max\n",
    "    colored = ((cells - magic_min) * 255) / norm_range\n",
    "    (r, g, b) = (colored[2], colored[1], colored[0])\n",
    "    alpha = np.full(r.shape, 255)\n",
    "    alpha[(cells[0] == tile.no_data_value) & \\\n",
    "          (cells[1] == tile.no_data_value) & \\\n",
    "          (cells[2] == tile.no_data_value)] = 0\n",
    "    rgba = np.dstack([r,g,b, alpha]).astype('uint8')\n",
    "    #return Image.fromarray(colored[1], mode='P')\n",
    "    return Image.fromarray(rgba, mode='RGBA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer = gps.query(\"s3://datahub-catalogs-us-east-1\", \n",
    "                  \"landsat-8-continental-us-2016\", \n",
    "                  layer_zoom=13,\n",
    "                  time_intervals=[datetime(2016, 6, 1, 0, 0, 0),\n",
    "                                  datetime(2016, 9, 1, 0, 0, 0)],\n",
    "                  query_geom=county_wm,\n",
    "                  num_partitions=1000).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cloud_masked = layer.to_numpy_rdd().mapValues(mask_clouds)\n",
    "\n",
    "mosaiced = cloud_masked.map(lambda tup: \\\n",
    "                           (gps.SpatialKey(tup[0].col, tup[0].row), \n",
    "                           (tup[0].instant, tup[1]))) \\\n",
    "                      .groupByKey() \\\n",
    "                      .mapValues(mosaic)\n",
    "\n",
    "mosaiced_layer = \\\n",
    "    gps.TiledRasterLayer.from_numpy_rdd(layer_type=gps.LayerType.SPATIAL, \n",
    "                                        numpy_rdd=mosaiced, \n",
    "                                        metadata=layer.layer_metadata, \n",
    "                                        zoom_level=layer.zoom_level)\n",
    "    \n",
    "mosaic_pyramid = mosaiced_layer \\\n",
    "                    .mask(county_wm) \\\n",
    "                    .repartition(100) \\\n",
    "                    .pyramid(resample_method=gps.ResampleMethod.BILINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tms_server = gps.TMS.build(mosaic_pyramid, display=render_image)\n",
    "\n",
    "p = county_ll.centroid\n",
    "M.set_center(p.x, p.y, 9)\n",
    "\n",
    "\n",
    "for l in M.layers:\n",
    "    M.remove_layer(l)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"mosaic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective 2: Find the time in the layer that has the highest average NDVI.\n",
    "\n",
    "Compute the NDVI values over your county for summer (don't forget to convert the cell type!). View that timeseries in a matplotlib graph. Then use the date with the highest average NDVI value to filter the layer into a spatial layer, and paint the NDVI values on the map.\n",
    "\n",
    "Remember that NDVI is:\n",
    "\n",
    "![ndvi eq](files/ndvi.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = layer.bands(bands[\"Red\"]).convert_data_type(gps.CellType.FLOAT64).cache()\n",
    "nir = layer.bands(bands[\"NIR\"]).convert_data_type(gps.CellType.FLOAT64).cache()\n",
    "\n",
    "ndvi = (nir - r) / (nir + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_series = { k: v for (k, v) in ndvi.mean_series(county_wm) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(time_series,  orient='index')\n",
    "df = df.dropna(axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_time = df[0].argmax().to_pydatetime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective 3: View the NDVI over the county for that date (where data is available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_ndvi_layer = ndvi.to_spatial_layer(target_time=max_time)\n",
    "pyramid = max_ndvi_layer.repartition(100).pyramid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tms_server = gps.TMS.build(pyramid, display=ndvi_color_map)\n",
    "\n",
    "for l in M.layers:\n",
    "    M.remove_layer(l)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"ndvi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit: Mosaic over the county, taking each pixel that has the higher NDVI\n",
    "\n",
    "Rewrite the mosaic function to always take the pixel with the higher NDVI value, and display that mosaic on the map. Use the numpy version NDVI provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_ndvi(cells):\n",
    "    cells = cells.astype(float)\n",
    "    red = cells[2]\n",
    "    ir = cells[3]\n",
    "    return  (ir - red) / (ir + red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mosaic_by_ndvi(tile1, tile2):\n",
    "    # Mosiac by taking whichever pixel has the greatest NDVI\n",
    "    cells1, cells2 = tile1.cells, tile2.cells\n",
    "    ndvi1 = compute_ndvi(cells1)\n",
    "    ndvi2 = compute_ndvi(cells2)\n",
    "    \n",
    "    result = cells1.copy()\n",
    " \n",
    "    result_bands = []\n",
    "    for band_idx in range(0, result.shape[0]):\n",
    "        band = result[band_idx]\n",
    "        np.copyto(band, \n",
    "                  cells2[band_idx], \n",
    "                  where=ndvi1 < ndvi2)\n",
    "        result_bands.append(band)\n",
    "\n",
    "    result = np.array(result_bands)    \n",
    "\n",
    "    return gps.Tile.from_numpy_array(result, no_data_value=tile1.no_data_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cloud_masked = layer.to_numpy_rdd().mapValues(mask_clouds)\n",
    "\n",
    "mosaiced = cloud_masked.map(lambda tup: \\\n",
    "                           (gps.SpatialKey(tup[0].col, tup[0].row), \n",
    "                           tup[1])) \\\n",
    "                       .reduceByKey(mosaic_by_ndvi)\n",
    "\n",
    "mosaiced_layer = \\\n",
    "    gps.TiledRasterLayer.from_numpy_rdd(layer_type=gps.LayerType.SPATIAL, \n",
    "                                        numpy_rdd=mosaiced, \n",
    "                                        metadata=layer.layer_metadata, \n",
    "                                        zoom_level=layer.zoom_level)\n",
    "    \n",
    "mosaic_pyramid = mosaiced_layer \\\n",
    "                    .mask(county_wm) \\\n",
    "                    .repartition(100) \\\n",
    "                    .pyramid(resample_method=gps.ResampleMethod.BILINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tms_server = gps.TMS.build(mosaic_pyramid, display=render_image)\n",
    "\n",
    "p = county_ll.centroid\n",
    "M.set_center(p.x, p.y, 9)\n",
    "\n",
    "for l in M.layers:\n",
    "    M.remove_layer(l)\n",
    "M.add_layer(TMSRasterData(tms_server), name=\"mosaic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoNotebook + GeoPySpark",
   "language": "python",
   "name": "geonotebook3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
